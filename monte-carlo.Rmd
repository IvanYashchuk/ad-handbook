# Monte Carlo Methods

Monte Carlo methods are used to compute high-dimensional integrals
corresponding to expectations.  For example, if $Y \in \mathbb{R}$ is
a real-valued random variable and $f:\mathbb{R} \rightarrow
\mathbb{R}$ is a real-valued function, then the expectation of the
function applied to the random variable is
$$
\mathbb{E}[f(y)]
= \int_{\mathbb{R}} f(y) \cdot p_Y(y) \, \textrm{d} y,
$$
where $p_Y(y)$ is the density function for $Y$.

Suppose it possible to generate a sequence of random draws
$$
y^{(1)}, \ldots, y^{(m)}, \ldots \sim p_Y(y)
$$
distributed according to $p_Y(y)$.  With these random draws, the
expectation may be reformulated as as the limit of the average
value of the function applied to the draws,
$$
\mathbb{E}[f(y)]
= 
\lim_{M \rightarrow \infty} \frac{1}{M} \sum_{m=1}^M f(y^{(m)}).
$$
Given finite computation time, an approximate result can be computed
for some fixed $M$ as
$$
\mathbb{E}[f(y)]
\approx \frac{1}{M} \sum_{m=1}^M f(y^{(m)}).
$$
This is known as a Monte Carlo method, after the casino of that name
in Monaco.

If the function $f(y)$ depends on other parameters $z$, e.g., $f(y) =
g(y, z)$ and derivatives are required of the expectation, they can be
moved inside the integral.  That is, taking the expetactation over random variable $Y$ and ddifferentiating with respect to $z$ yields
$$
\frac{\partial}{\partial z} \mathbb{E}[g(y, z)]
= \mathbb{E}\left[ \frac{\partial}{\partial z} g(y, z) \right].
$$
The Monte Carlo approach is to approximate the derivative with
$$
\frac{\partial}{\partial z} \mathbb{E}[g(y, z)]
\approx
\frac{1}{M} \sum_{m=1}^M \frac{\partial}{\partial z} g(y^{(m)}, z).
$$

The internal derivative $\frac{\partial}{\partial z}g(y^{(m)}, z)$ may
be computed via automatic differentiation and the results summed.  No
new rules of automatic differentiation are required, as the resulting
term is a simple sum.

## Max marginal optimization and sampling

A common application for Monte Carlo integration is computing marginal
densities, 
$$
p_{\Phi}(\phi) = \int_{\mathbb{R}} p_{\Phi,\Theta}(\phi, \theta) \, \textrm{d}\theta,
$$
for a given input value $\phi$.  A Monte Carlo approximation can be
calculated as
$$
p_{\Phi}(\phi)
\approx
\frac{1}{M} \sum_{m = 1}^M
  p_{\Phi, \Theta}(\phi, \theta^{(m)}),
$$
where for $m \in 1:M,$
$$
\theta^{(m)} \sim p_{\Theta \mid \Phi}(\theta \mid \phi).
$$

Gradient-based samplers or optimizers when $\Phi$ is multivariate
require the gradient $\nabla p_{\Phi}(\phi)$.  This can be
calculated via Monte Carlo as
$$
\nabla p_{\Phi}(\phi)
\approx
\frac{1}{M} \sum_{m=1}^M
  \nabla p_{\Phi, \Theta}(\phi, \theta^{(m)}).
$$

For example, the maximum marginal likelihood estimate $\phi^*$ is
defined as an optimization,

$$
\phi^* = \textrm{arg max}_{\phi} \ p_{\Phi}(\phi).
$$
Optimizing $p_{\Phi}$ with the marginalization computed
by Markov chain Monte Carlo methods leads to an algorithm known as
Markov chain Monte Carlo expectation maximization (MCMC-EM).

## Stochastic gradients

These are all examples of stochastic gradient calculations.  

